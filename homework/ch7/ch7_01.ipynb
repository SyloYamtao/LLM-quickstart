{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sat Jun 29 11:15:18 2024       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:15:00.0 Off |                  Off |\n",
    "| 30%   54C    P2             330W / 450W |  24062MiB / 24564MiB |     99%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:18:00.0 Off |                  Off |\n",
    "| 30%   34C    P2              56W / 450W |  14394MiB / 24564MiB |      0%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "+---------------------------------------------------------------------------------------+"
   ],
   "id": "755e79b2b764ad45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f66753-e979-431d-9c79-ea041bbee4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载完成\n",
      "特征提取器加载完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词器加载完成\n",
      "处理器加载完成\n",
      "数据预处理完成\n",
      "数据预处理应用完成\n",
      "数据整理器实例化完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载和配置完成\n",
      "LoRA配置完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/root/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/root/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='454' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/454 1:16:15 < 58:22, 0.06 it/s, Epoch 0.57/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, Training Loss: 1.4941, Validation Loss: None\n",
      "Step: 20, Training Loss: 0.5236, Validation Loss: None\n",
      "Step: 30, Training Loss: 0.4354, Validation Loss: None\n",
      "Step: 40, Training Loss: 0.4068, Validation Loss: None\n",
      "Step: 50, Training Loss: 0.4098, Validation Loss: None\n",
      "Step: 60, Training Loss: 0.3706, Validation Loss: None\n",
      "Step: 70, Training Loss: 0.4023, Validation Loss: None\n",
      "Step: 80, Training Loss: 0.3496, Validation Loss: None\n",
      "Step: 90, Training Loss: 0.4164, Validation Loss: None\n",
      "Step: 100, Training Loss: 0.35, Validation Loss: None\n",
      "Step: 110, Training Loss: 0.319, Validation Loss: None\n",
      "Step: 120, Training Loss: 0.3467, Validation Loss: None\n",
      "Step: 130, Training Loss: 0.3424, Validation Loss: None\n",
      "Step: 140, Training Loss: 0.3512, Validation Loss: None\n",
      "Step: 150, Training Loss: 0.3087, Validation Loss: None\n",
      "Step: 160, Training Loss: 0.3456, Validation Loss: None\n",
      "Step: 170, Training Loss: 0.3796, Validation Loss: None\n",
      "Step: 180, Training Loss: 0.3303, Validation Loss: None\n",
      "Step: 190, Training Loss: 0.3343, Validation Loss: None\n",
      "Step: 200, Training Loss: 0.3761, Validation Loss: None\n",
      "Step: 210, Training Loss: 0.34, Validation Loss: None\n",
      "Step: 220, Training Loss: 0.3207, Validation Loss: None\n",
      "Step: 230, Training Loss: 0.3663, Validation Loss: None\n",
      "Step: 240, Training Loss: 0.3853, Validation Loss: None\n",
      "Step: 250, Training Loss: 0.3604, Validation Loss: None\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "from transformers import AutoFeatureExtractor, AutoTokenizer, AutoProcessor, AutoModelForSpeechSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, TrainerCallback\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model, PeftModel ,PeftConfig\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "# 全局参数设置\n",
    "base_path = \"/root/dataDisk/hf/hub\"\n",
    "model_name_or_path = base_path + \"/models/whisper-large-v2\"\n",
    "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "task = \"transcribe\"\n",
    "dataset_path = base_path +\"/datasets/common_voice_11_0/\"\n",
    "batch_size = 64\n",
    "\n",
    "# 加载数据集\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(dataset_path+\"common_voice_11_0.py\", language_abbr, split=\"train\", cache_dir=dataset_path, trust_remote_code=True)\n",
    "common_voice[\"validation\"] = load_dataset(dataset_path+\"common_voice_11_0.py\", language_abbr, split=\"validation\", cache_dir=dataset_path, trust_remote_code=True)\n",
    "\n",
    "print(\"数据集加载完成\")\n",
    "\n",
    "# 数据预处理\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "print(\"特征提取器加载完成\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "print(\"分词器加载完成\")\n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "print(\"处理器加载完成\")\n",
    "\n",
    "# 移除数据集中不必要的字段\n",
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "print(\"数据预处理完成\")\n",
    "\n",
    "# 数据预处理函数\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# 应用数据预处理\n",
    "tokenized_common_voice = common_voice.map(prepare_dataset, num_proc=2)\n",
    "\n",
    "print(\"数据预处理应用完成\")\n",
    "\n",
    "# 数据整理器定义\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "print(\"数据整理器实例化完成\")\n",
    "\n",
    "# 加载和配置模型\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "print(\"模型加载和配置完成\")\n",
    "\n",
    "# LoRA配置\n",
    "config = LoraConfig(\n",
    "    r=4, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "peft_model = get_peft_model(model, config)\n",
    "\n",
    "print(\"LoRA配置完成\")\n",
    "\n",
    "# 自定义回调类\n",
    "class TrainEvalCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        # 打印训练和验证损失\n",
    "        print(f\"Step: {state.global_step}, Training Loss: {logs.get('loss', None)}, Validation Loss: {logs.get('eval_loss', None)}\")\n",
    "\n",
    "# 训练设置\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_dir, per_device_train_batch_size=batch_size, learning_rate=1e-3,\n",
    "    num_train_epochs=1, evaluation_strategy=\"epoch\", per_device_eval_batch_size=batch_size,\n",
    "    generation_max_length=128, logging_steps=10, remove_unused_columns=False, label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args, model=peft_model, train_dataset=tokenized_common_voice[\"train\"],\n",
    "    eval_dataset=tokenized_common_voice[\"validation\"], data_collator=data_collator, tokenizer=processor.feature_extractor, callbacks=[TrainEvalCallback]  # 添加自定义回调\n",
    ")\n",
    "peft_model.config.use_cache = False\n",
    "trainer.train()\n",
    "trainer.save_model(model_dir)\n",
    "\n",
    "print(\"模型训练和保存完成\")\n",
    "\n",
    "# 清理 GPU 内存\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 指定设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 重新加载模型\n",
    "peft_config = LoraConfig.from_pretrained(model_dir)\n",
    "base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, \n",
    "    load_in_8bit=True, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "peft_model = PeftModel.from_pretrained(base_model, model_dir)\n",
    "peft_model.to(device)  # 将模型移动到指定设备\n",
    "peft_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "feature_extractor = processor.feature_extractor\n",
    "\n",
    "# 语音识别管道\n",
    "test_audio = \"data/audio/test_zh.flac\"\n",
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "    model=peft_model, \n",
    "    tokenizer=tokenizer, \n",
    "    feature_extractor=feature_extractor,\n",
    "    device=device  # 指定设备\n",
    ")\n",
    "\n",
    "# 读取音频文件\n",
    "import librosa\n",
    "audio, rate = librosa.load(test_audio, sr=16000)\n",
    "\n",
    "# 进行推理\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    inputs = feature_extractor(audio, sampling_rate=rate, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = peft_model.generate(inputs=inputs[\"input_features\"])\n",
    "    transcription = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95da3a-b8b7-4d63-8f44-f02dbbb75ccf",
   "metadata": {},
   "source": [
    "### 运行结果\n",
    "```PLAINTEXT\n",
    "数据集加载完成\n",
    "特征提取器加载完成\n",
    "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
    "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
    "分词器加载完成\n",
    "处理器加载完成\n",
    "数据预处理完成\n",
    "数据预处理应用完成\n",
    "数据整理器实例化完成\n",
    "/root/.local/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
    "  warnings.warn(\n",
    "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
    "模型加载和配置完成\n",
    "LoRA配置完成\n",
    "/root/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
    "  warnings.warn(\n",
    "/root/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
    "  warnings.warn(\n",
    " [454/454 2:42:35, Epoch 1/1]\n",
    "Epoch\tTraining Loss\tValidation Loss\n",
    "1\t0.326500\t0.385433\n",
    "Step: 10, Training Loss: 1.4963, Validation Loss: None\n",
    "Step: 20, Training Loss: 0.474, Validation Loss: None\n",
    "Step: 30, Training Loss: 0.4387, Validation Loss: None\n",
    "Step: 40, Training Loss: 0.4131, Validation Loss: None\n",
    "Step: 50, Training Loss: 0.4139, Validation Loss: None\n",
    "Step: 60, Training Loss: 0.3713, Validation Loss: None\n",
    "Step: 70, Training Loss: 0.4005, Validation Loss: None\n",
    "Step: 80, Training Loss: 0.3485, Validation Loss: None\n",
    "Step: 90, Training Loss: 0.4171, Validation Loss: None\n",
    "Step: 100, Training Loss: 0.3476, Validation Loss: None\n",
    "Step: 110, Training Loss: 0.3189, Validation Loss: None\n",
    "Step: 120, Training Loss: 0.3429, Validation Loss: None\n",
    "Step: 130, Training Loss: 0.3466, Validation Loss: None\n",
    "Step: 140, Training Loss: 0.3538, Validation Loss: None\n",
    "Step: 150, Training Loss: 0.3062, Validation Loss: None\n",
    "Step: 160, Training Loss: 0.3447, Validation Loss: None\n",
    "Step: 170, Training Loss: 0.3759, Validation Loss: None\n",
    "Step: 180, Training Loss: 0.3284, Validation Loss: None\n",
    "Step: 190, Training Loss: 0.3307, Validation Loss: None\n",
    "Step: 200, Training Loss: 0.3748, Validation Loss: None\n",
    "Step: 210, Training Loss: 0.3425, Validation Loss: None\n",
    "Step: 220, Training Loss: 0.3201, Validation Loss: None\n",
    "Step: 230, Training Loss: 0.3682, Validation Loss: None\n",
    "Step: 240, Training Loss: 0.3846, Validation Loss: None\n",
    "Step: 250, Training Loss: 0.3589, Validation Loss: None\n",
    "Step: 260, Training Loss: 0.364, Validation Loss: None\n",
    "Step: 270, Training Loss: 0.3685, Validation Loss: None\n",
    "Step: 280, Training Loss: 0.3167, Validation Loss: None\n",
    "Step: 290, Training Loss: 0.4082, Validation Loss: None\n",
    "Step: 300, Training Loss: 0.3292, Validation Loss: None\n",
    "Step: 310, Training Loss: 0.3433, Validation Loss: None\n",
    "Step: 320, Training Loss: 0.3413, Validation Loss: None\n",
    "Step: 330, Training Loss: 0.3601, Validation Loss: None\n",
    "Step: 340, Training Loss: 0.3271, Validation Loss: None\n",
    "Step: 350, Training Loss: 0.3237, Validation Loss: None\n",
    "Step: 360, Training Loss: 0.3121, Validation Loss: None\n",
    "Step: 370, Training Loss: 0.3099, Validation Loss: None\n",
    "Step: 380, Training Loss: 0.3259, Validation Loss: None\n",
    "Step: 390, Training Loss: 0.3085, Validation Loss: None\n",
    "Step: 400, Training Loss: 0.293, Validation Loss: None\n",
    "Step: 410, Training Loss: 0.3535, Validation Loss: None\n",
    "Step: 420, Training Loss: 0.3815, Validation Loss: None\n",
    "Step: 430, Training Loss: 0.346, Validation Loss: None\n",
    "Step: 440, Training Loss: 0.3522, Validation Loss: None\n",
    "Step: 450, Training Loss: 0.3265, Validation Loss: None\n",
    "Step: 454, Training Loss: None, Validation Loss: 0.3854326605796814\n",
    "Step: 454, Training Loss: None, Validation Loss: None\n",
    "模型训练和保存完成\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_peft",
   "language": "python",
   "name": "new_peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
